geometry:
  generator:
    type: icosa        # one of: icosa | dodeca | octa | tetra | random
    # N: 12              # only for random
    # seed: 777          # only for random
  centers:             # ignored if generator is defined above
    ## calculated centers can be listed here to avoid recalculation on each run
    # - [0.0, 0.5020732120737726, 0.8123715219761982, 1.0, 0.6]
    # - [0.0, -0.5020732120737726, 0.8123715219761982, 1.0, 0.6]
    # - [0.0, 0.5020732120737726, -0.8123715219761982, 1.0, 0.6]
    # - [0.0, -0.5020732120737726, -0.8123715219761982, 1.0, 0.6]
    # - [0.5020732120737726, 0.8123715219761982, 0.0, 1.0, 0.6]
    # - [-0.5020732120737726, 0.8123715219761982, 0.0, 1.0, 0.6]
    # - [0.5020732120737726, -0.8123715219761982, 0.0, 1.0, 0.6]
    # - [-0.5020732120737726, -0.8123715219761982, 0.0, 1.0, 0.6]
    # - [0.8123715219761982, 0.0, 0.5020732120737726, 1.0, 0.6]
    # - [0.8123715219761982, 0.0, -0.5020732120737726, 1.0, 0.6]
    # - [-0.8123715219761982, 0.0, 0.5020732120737726, 1.0, 0.6]
    # - [-0.8123715219761982, 0.0, -0.5020732120737726, 1.0, 0.6]
  alpha_metric: 0.58
  beta_floor: 0.68
  lambda_su2: 0.190
  nu_su3: 0.445
  domain: [[-2.5, 2.5], [-2.5, 2.5], [-2.5, 2.5]]
  n_samples: 1_000_000
  rng_seed: 7777
  metric_model: hessian_logV   # or: grad_outer
  weight_form: sqrt_detG
  jitter: 1.0e-9

ew_anchor:
  mu0: 150.0
  alpha_em_mu0: 0.007820   # 1/127.955
  sin2_thetaW_mu0: 0.2312
  scheme: Q3  #Q0 or Q3

oc_params:
  kappa: {"U1": 2, "SU2": 1, "SU3": 1}
  weights: {"U1": 0.6, "SU2": 1.0, "SU3": 1.0}
  n_color_discrete: 2
  lock_modes: EW
  Ka_mode: slope
  Ka_slope_K0: 0.475  #calculated once as universal value
  Ka_prefactor: 1.0
  Ka_power_kappa: 2.0
  Ka_divide_by_n: true
  Ka_group_scale: {"U1": 1.0, "SU2": 1.0, "SU3": 0.242284388589654}
  m_tau_prefactor: 1.0
  m_tau_kappa_agg: sum    # sum |kappa_a|
  m_tau_kappa_power: 0.5  # √(…)
  m_tau_x_exponent: 0.5   # √x


rg:
  mu_target: 91.1876
  loop_order: 2
  n_steps: 4000

frg_scan:
  flow: projector_bf  # projector_bf | toy (keep 'toy' to use the old ODE)
  kmin: 0.03
  kmax: 150.0
  n_k: 2200
  #####
  # - Only used when flow is 'toy'
  # alpha_target: 5
  # model: projected
  # growth_c: 1.6
  #####
  eta_freeze: 0.25
  alpha_cap: 5.0

compute:
  backend: numpy     # options: torch_mps | torch_cpu | numpy
  batch_size: 128000      # tune per GPU memory; 32k–128k are good starting points
  dtype: float32         # MPS prefers float32; keep metrics stable with jitter
